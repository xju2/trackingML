{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trackml.dataset import load_event\n",
    "from trackml.randomize import shuffle_hits\n",
    "from trackml.score import score_event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18728, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import make_uID\n",
    "det = pd.read_csv('input/detectors.csv')\n",
    "det.head()\n",
    "hits_pd = make_uID(det)\n",
    "hits_pd.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load one event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_prefix = 'event000001000'\n",
    "hits, cells, particles, truth = load_event(os.path.join('input/train_1', event_prefix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hit_id</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>volume_id</th>\n",
       "      <th>layer_id</th>\n",
       "      <th>module_id</th>\n",
       "      <th>uID</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>z2</th>\n",
       "      <th>r2</th>\n",
       "      <th>r</th>\n",
       "      <th>eta</th>\n",
       "      <th>phi</th>\n",
       "      <th>absZ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-64.409897</td>\n",
       "      <td>-7.163700</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.042829</td>\n",
       "      <td>-0.004763</td>\n",
       "      <td>-23.184208</td>\n",
       "      <td>64.807045</td>\n",
       "      <td>1503.896973</td>\n",
       "      <td>-3.837108</td>\n",
       "      <td>-3.030827</td>\n",
       "      <td>1502.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-55.336102</td>\n",
       "      <td>0.635342</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.036804</td>\n",
       "      <td>0.000423</td>\n",
       "      <td>-27.150467</td>\n",
       "      <td>55.339748</td>\n",
       "      <td>1503.518799</td>\n",
       "      <td>-3.994889</td>\n",
       "      <td>3.130112</td>\n",
       "      <td>1502.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>-83.830498</td>\n",
       "      <td>-1.143010</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.055707</td>\n",
       "      <td>-0.000760</td>\n",
       "      <td>-17.921406</td>\n",
       "      <td>83.838287</td>\n",
       "      <td>1504.837158</td>\n",
       "      <td>-3.579932</td>\n",
       "      <td>-3.127959</td>\n",
       "      <td>1502.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>-96.109100</td>\n",
       "      <td>-8.241030</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.063835</td>\n",
       "      <td>-0.005474</td>\n",
       "      <td>-15.576118</td>\n",
       "      <td>96.461777</td>\n",
       "      <td>1505.593262</td>\n",
       "      <td>-3.439919</td>\n",
       "      <td>-3.056055</td>\n",
       "      <td>1502.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>-62.673599</td>\n",
       "      <td>-9.371200</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.041676</td>\n",
       "      <td>-0.006232</td>\n",
       "      <td>-23.709833</td>\n",
       "      <td>63.370335</td>\n",
       "      <td>1503.835815</td>\n",
       "      <td>-3.859459</td>\n",
       "      <td>-2.993168</td>\n",
       "      <td>1502.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hit_id          x         y       z  volume_id  layer_id  module_id  uID  \\\n",
       "0       1 -64.409897 -7.163700 -1502.5          7         2          1    0   \n",
       "1       2 -55.336102  0.635342 -1502.5          7         2          1    0   \n",
       "2       3 -83.830498 -1.143010 -1502.5          7         2          1    0   \n",
       "3       4 -96.109100 -8.241030 -1502.5          7         2          1    0   \n",
       "4       5 -62.673599 -9.371200 -1502.5          7         2          1    0   \n",
       "\n",
       "         x2        y2         z2         r2            r       eta       phi  \\\n",
       "0 -0.042829 -0.004763 -23.184208  64.807045  1503.896973 -3.837108 -3.030827   \n",
       "1 -0.036804  0.000423 -27.150467  55.339748  1503.518799 -3.994889  3.130112   \n",
       "2 -0.055707 -0.000760 -17.921406  83.838287  1504.837158 -3.579932 -3.127959   \n",
       "3 -0.063835 -0.005474 -15.576118  96.461777  1505.593262 -3.439919 -3.056055   \n",
       "4 -0.041676 -0.006232 -23.709833  63.370335  1503.835815 -3.859459 -2.993168   \n",
       "\n",
       "     absZ  \n",
       "0  1502.5  \n",
       "1  1502.5  \n",
       "2  1502.5  \n",
       "3  1502.5  \n",
       "4  1502.5  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hits_with_uID = pd.merge(hits, hits_pd, on=['volume_id', 'layer_id', 'module_id'])\n",
    "from utils import get_features\n",
    "hits_final = get_features(hits_with_uID)\n",
    "hits_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_truth = truth[ (truth['weight'] > 5e-7 ) & (truth['particle_id'] != 0) ]\n",
    "training = hits_final.merge(filtered_truth, on='hit_id')[['uID', 'particle_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total particles: 9292\n"
     ]
    }
   ],
   "source": [
    "truth_particles = pd.Series(np.unique(training['particle_id']))\n",
    "print(\"total particles:\", truth_particles.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try the RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HitPredictor(nn.Module):\n",
    "    def __init__(self, input_dim=20, hidden_dim=20, output_dim=20,\n",
    "                n_lstm_layers=1):\n",
    "        super(HitPredictor, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.batch_size = 1\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, n_lstm_layers)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.hidden = self.init_hidden()\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return (torch.zeros(self.lstm.num_layers, self.batch_size, self.hidden_dim),\n",
    "                torch.zeros(self.lstm.num_layers, self.batch_size, self.hidden_dim))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        input_size = x.size()\n",
    "        output, self.hidden = self.lstm(x, self.hidden)\n",
    "        output = self.fc(output.view(len(x), -1))\n",
    "        tag_scores = self.softmax(output)\n",
    "        return tag_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HitPredictor(nn.Module):\n",
    "    def __init__(self, input_dim=20, hidden_dim=20, output_dim=20,\n",
    "                n_lstm_layers=1):\n",
    "        super(HitPredictor, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.batch_size = 1\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, n_lstm_layers)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.hidden = self.init_hidden()\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return (torch.zeros(self.lstm.num_layers, self.batch_size, self.hidden_dim),\n",
    "                torch.zeros(self.lstm.num_layers, self.batch_size, self.hidden_dim))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        input_size = x.size()\n",
    "        output, self.hidden = self.lstm(x, self.hidden)\n",
    "        output = self.fc(output.view(len(x), -1))\n",
    "        tag_scores = self.softmax(output)\n",
    "        return tag_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_modules = 18728"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inputHits(series):\n",
    "    tensor = torch.zeros(len(series), 1, total_modules+1)\n",
    "    for idx, h in enumerate(series):\n",
    "        tensor[idx][0][h] = 1\n",
    "\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def targetHits(series):\n",
    "    module_idx = series[1:].tolist()\n",
    "    module_idx.append(total_modules)\n",
    "    # module_idx += [total_modules]*(21 - len(series))\n",
    "    return torch.LongTensor(module_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomTrack():\n",
    "    pID = truth_particles.sample(1).values\n",
    "    hit_series = training[training['particle_id'] == pID[0]]['uID'].values\n",
    "    input_tensor = inputHits(hit_series)\n",
    "    target_tensor = targetHits(hit_series)\n",
    "    return input_tensor, target_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getInputTarget(hit_series):\n",
    "    input_tensor = inputHits(hit_series)\n",
    "    target_tensor = targetHits(hit_series)\n",
    "    return input_tensor, target_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 1, 18729])\n",
      "12\n",
      "torch.Size([12])\n"
     ]
    }
   ],
   "source": [
    "input2_, target2_ = randomTrack()\n",
    "print(input2_.size())\n",
    "print(len(input2_))\n",
    "print(target2_.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_result(input_, tags_, target_):\n",
    "    with torch.no_grad():\n",
    "        print(\"inputs:\", torch.reshape(torch.argmax(input_, dim=2), (-1,)))\n",
    "        print(\"predictions:\", torch.argmax(tags_, dim=1))\n",
    "        print(\"target:\", target_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train RNN with all tracks in this event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3m 44s (0 0%) 9.8405\n",
      "inputs: tensor([   864,   1197,   1729,   2608,   5376,   6358,   7652,  15401])\n",
      "predictions: tensor([  1629,   7613,   7613,   7613,   7613,  16516,   1629,   1629])\n",
      "target: tensor([  1197,   1729,   2608,   5376,   6358,   7652,  15401,  18728])\n",
      "45m 34s (10 10%) 9.8344\n",
      "inputs: tensor([   77,   185,   292,   400,   508,   616,   618,   724,   726,\n",
      "         4122])\n",
      "predictions: tensor([ 12334,   1791,   1791,   1791,   1791,   1789,   1789,   1789,\n",
      "          1789,   1789])\n",
      "target: tensor([   185,    292,    400,    508,    616,    618,    724,    726,\n",
      "          4122,  18728])\n",
      "85m 38s (20 20%) 9.8351\n",
      "inputs: tensor([   853,   1175,   1693,   2475,   5347,   6261,   7514,   9196,\n",
      "         12797,  15262])\n",
      "predictions: tensor([ 18728,  18728,  18728,  18728,  18728,  18728,  18728,  18728,\n",
      "         18728,  18728])\n",
      "target: tensor([  1175,   1693,   2475,   5347,   6261,   7514,   9196,  12797,\n",
      "         15262,  18728])\n",
      "129m 8s (30 30%) 9.8369\n",
      "inputs: tensor([   854,   1177,   1749,   2638,   2639,   5431,   5432,   6435,\n",
      "          7759,   7837,   9620,  13538,  16358])\n",
      "predictions: tensor([ 18728,  18728,  18728,  18728,  18728,  18728,  18728,  18728,\n",
      "         18728,  18728,  18728,  18728,  18728])\n",
      "target: tensor([  1177,   1749,   2638,   2639,   5431,   5432,   6435,   7759,\n",
      "          7837,   9620,  13538,  16358,  18728])\n",
      "173m 54s (40 40%) 9.8343\n",
      "inputs: tensor([   864,   1196,   1780,   2684,   5414,   5415,   5455,   6411,\n",
      "          7802,   9674,  13480,  16280])\n",
      "predictions: tensor([ 18728,  18728,  18728,  18728,  18728,  18728,  18728,  18728,\n",
      "         18728,  18728,  18728,  18728])\n",
      "target: tensor([  1196,   1780,   2684,   5414,   5415,   5455,   6411,   7802,\n",
      "          9674,  13480,  16280,  18728])\n",
      "225m 43s (50 50%) 9.8341\n",
      "inputs: tensor([   840,   1085,   1116,   1546,   2177,   4566,   4734,   4904,\n",
      "          5155,   5880,  11967,  11968,  11969])\n",
      "predictions: tensor([ 18728,  18728,  18728,  18728,  18728,  18728,  18728,  18728,\n",
      "         18728,  18728,  18728,  18728,  18728])\n",
      "target: tensor([  1085,   1116,   1546,   2177,   4566,   4734,   4904,   5155,\n",
      "          5880,  11967,  11968,  11969,  18728])\n",
      "271m 55s (60 60%) 9.8322\n",
      "inputs: tensor([   868,   1268,   1949,   3093,   5624,   6816,   6872,   8600,\n",
      "         10822,  10992,  18432,  18531])\n",
      "predictions: tensor([ 18728,  18728,  18728,  18728,  18728,  18728,  18728,  18728,\n",
      "         18728,  18728,  18728,  18728])\n",
      "target: tensor([  1268,   1949,   3093,   5624,   6816,   6872,   8600,  10822,\n",
      "         10992,  18432,  18531,  18728])\n",
      "308m 47s (70 70%) 9.8297\n",
      "inputs: tensor([  166,   274,   382,   489,   597,   705,   812,  4096,  4266,\n",
      "         4436])\n",
      "predictions: tensor([ 18728,  18728,  18728,  18728,  18728,  18728,  18728,  18728,\n",
      "         18728,  18728])\n",
      "target: tensor([   274,    382,    489,    597,    705,    812,   4096,   4266,\n",
      "          4436,  18728])\n",
      "349m 32s (80 80%) 9.8255\n",
      "inputs: tensor([  3307,   3310,   3415,   3418,   3523,   3631,   3739,   3849,\n",
      "          3957,  11766])\n",
      "predictions: tensor([ 18728,  18728,  18728,  18728,  18728,  18728,  18728,  18728,\n",
      "         18728,  18728])\n",
      "target: tensor([  3310,   3415,   3418,   3523,   3631,   3739,   3849,   3957,\n",
      "         11766,  18728])\n",
      "383m 46s (90 90%) 9.8284\n",
      "inputs: tensor([   857,   1183,   1706,   2574,   5359,   6277,   6333,   6334,\n",
      "          7618,   9232,  12963,  15328])\n",
      "predictions: tensor([ 18728,  18728,  18728,  18728,  18728,  18728,  18728,  18728,\n",
      "         18728,  18728,  18728,  18728])\n",
      "target: tensor([  1183,   1706,   2574,   5359,   6277,   6333,   6334,   7618,\n",
      "          9232,  12963,  15328,  18728])\n",
      "I am done\n"
     ]
    }
   ],
   "source": [
    "n_iters = truth_particles.shape[0]\n",
    "\n",
    "n_iters = 100\n",
    "print_every = n_iters/10\n",
    "plot_every = 200\n",
    "all_losses = []\n",
    "total_loss = 0\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "rnn = HitPredictor(input_dim=total_modules+1, hidden_dim=total_modules+1, \n",
    "                   output_dim=total_modules+1,\n",
    "                   n_lstm_layers=2)\n",
    "optimizer = optim.SGD(rnn.parameters(), lr=0.01)\n",
    "\n",
    "for iter_ in range(n_iters):\n",
    "    pID = truth_particles.values[iter_]\n",
    "\n",
    "    # prepare the inputs\n",
    "    input_, target_ = getInputTarget(training[training['particle_id'] == pID]['uID'].values)\n",
    "    \n",
    "    # training\n",
    "    rnn.zero_grad()\n",
    "    rnn.hidden = rnn.init_hidden()\n",
    "    tag_scores = rnn(input_)\n",
    "    \n",
    "    loss = criterion(tag_scores, target_)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    total_loss += loss\n",
    "    if iter_ % print_every == 0:\n",
    "        print('%s (%d %d%%) %.4f' % (timeSince(start), iter_, iter_ / n_iters * 100, loss))\n",
    "        check_result(input_, tag_scores, target_)\n",
    "        \n",
    "    if iter_ % plot_every == 0:\n",
    "        all_losses.append(total_loss / plot_every)\n",
    "        total_loss = 0\n",
    "\n",
    "print(\"I am done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_nhits = 20\n",
    "def check_training(start_hit):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = inputHits([start_hit])\n",
    "        print(input_tensor.size())\n",
    "        print(input_tensor[0][0][start_hit])\n",
    "        rnn.hidden = rnn.init_hidden()\n",
    "        out_hits = []\n",
    "        for i in range(max_nhits):\n",
    "            output = rnn(input_tensor)\n",
    "            topv, topi = output.topk(1)\n",
    "            topi = topi[0][0]\n",
    "            if topi == total_modules:\n",
    "                print(\"Hit the last hits\")\n",
    "                break\n",
    "            else:\n",
    "                out_hits.append(topi)\n",
    "            input_tensor = inputHits([topi])\n",
    "        return out_hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 18729])\n",
      "tensor(1.)\n",
      "Hit the last hits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_training(3456)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(rnn.state_dict(), \"trained_1event_rnn_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_, target = randomTrack()\n",
    "rnn = HitPredictor(input_dim=total_modules+1, hidden_dim=512, output_dim=total_modules+1)\n",
    "n_iters = 100\n",
    "print_every = 10\n",
    "all_losses = []\n",
    "total_loss = 0\n",
    "\n",
    "#target.unsqueeze_(-1)\n",
    "rnn.hidden = rnn.init_hidden()\n",
    "\n",
    "rnn.zero_grad()\n",
    "loss = 0\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "print(\"input size:\", input_.size())\n",
    "print('target size:', target.size())\n",
    "output = rnn(input_)\n",
    "print(\"output size:\", output.size())\n",
    "print(target)\n",
    "loss = criterion(output, target)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1])\n",
      "torch.FloatTensor\n",
      "torch.float32\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-a5513195d698>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mh0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mc0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mh0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/global/project/projectdirs/m1092/xju/miniconda3/envs/py3.6/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/global/project/projectdirs/m1092/xju/miniconda3/envs/py3.6/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0mbatch_sizes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             \u001b[0mmax_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_first\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "rnn2 = nn.LSTM(6, 20)\n",
    "input = torch.randn(1)\n",
    "print(input.size())\n",
    "print(input.type())\n",
    "print(input.dtype)\n",
    "h0 = torch.randn(2, 1, 20)\n",
    "c0 = torch.randn(2, 1, 20)\n",
    "output, hn = rnn2(input, (h0, c0))\n",
    "print(output)\n",
    "print(output.size())\n",
    "print(hn)\n",
    "print(hn[0].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.LogSoftmax(dim=1)\n",
    "loss = nn.NLLLoss()\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.tensor([1, 0, 4])\n",
    "print(target.size())\n",
    "print(m(input).size())\n",
    "output = loss(m(input), target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1,  2,  4,  5])\n"
     ]
    }
   ],
   "source": [
    "embedding = nn.Embedding(10, 3)\n",
    "input = torch.LongTensor([1,2,4,5])\n",
    "print(input)\n",
    "embeds = embedding(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3])\n",
      "torch.Size([4])\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "print(embeds.size())\n",
    "print(input.size())\n",
    "print(len(input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5956, -0.3846,  0.6718],\n",
      "        [ 0.4788,  0.3929,  0.4087],\n",
      "        [ 0.3090,  0.4232,  1.3487],\n",
      "        [ 2.1231, -0.9157, -1.3121]])\n",
      "tensor([[[-0.5956, -0.3846,  0.6718]],\n",
      "\n",
      "        [[ 0.4788,  0.3929,  0.4087]],\n",
      "\n",
      "        [[ 0.3090,  0.4232,  1.3487]],\n",
      "\n",
      "        [[ 2.1231, -0.9157, -1.3121]]])\n",
      "torch.Size([4, 1, 3])\n"
     ]
    }
   ],
   "source": [
    "print(embeds)\n",
    "new_embeds = embeds.view(len(input), 1, -1)\n",
    "print(new_embeds)\n",
    "print(new_embeds.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TrackPy3.6",
   "language": "python",
   "name": "trackkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
