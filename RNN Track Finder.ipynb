{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trackml.dataset import load_event\n",
    "from trackml.randomize import shuffle_hits\n",
    "from trackml.score import score_event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18728\n"
     ]
    }
   ],
   "source": [
    "from utils import make_uID\n",
    "det = pd.read_csv('input/detectors.csv')\n",
    "det.head()\n",
    "hits_pd = make_uID(det)\n",
    "total_modules = hits_pd.shape[0]\n",
    "print(total_modules)\n",
    "max_nhits = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load one event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_prefix = 'event000001000'\n",
    "hits, cells, particles, truth = load_event(os.path.join('input/train_1', event_prefix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hit_id</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>volume_id</th>\n",
       "      <th>layer_id</th>\n",
       "      <th>module_id</th>\n",
       "      <th>uID</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>z2</th>\n",
       "      <th>r2</th>\n",
       "      <th>r</th>\n",
       "      <th>eta</th>\n",
       "      <th>phi</th>\n",
       "      <th>absZ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-64.409897</td>\n",
       "      <td>-7.163700</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.042829</td>\n",
       "      <td>-0.004763</td>\n",
       "      <td>-23.184208</td>\n",
       "      <td>64.807045</td>\n",
       "      <td>1503.896973</td>\n",
       "      <td>-3.837108</td>\n",
       "      <td>-3.030827</td>\n",
       "      <td>1502.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-55.336102</td>\n",
       "      <td>0.635342</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.036804</td>\n",
       "      <td>0.000423</td>\n",
       "      <td>-27.150467</td>\n",
       "      <td>55.339748</td>\n",
       "      <td>1503.518799</td>\n",
       "      <td>-3.994889</td>\n",
       "      <td>3.130112</td>\n",
       "      <td>1502.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>-83.830498</td>\n",
       "      <td>-1.143010</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.055707</td>\n",
       "      <td>-0.000760</td>\n",
       "      <td>-17.921406</td>\n",
       "      <td>83.838287</td>\n",
       "      <td>1504.837158</td>\n",
       "      <td>-3.579932</td>\n",
       "      <td>-3.127959</td>\n",
       "      <td>1502.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>-96.109100</td>\n",
       "      <td>-8.241030</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.063835</td>\n",
       "      <td>-0.005474</td>\n",
       "      <td>-15.576118</td>\n",
       "      <td>96.461777</td>\n",
       "      <td>1505.593262</td>\n",
       "      <td>-3.439919</td>\n",
       "      <td>-3.056055</td>\n",
       "      <td>1502.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>-62.673599</td>\n",
       "      <td>-9.371200</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.041676</td>\n",
       "      <td>-0.006232</td>\n",
       "      <td>-23.709833</td>\n",
       "      <td>63.370335</td>\n",
       "      <td>1503.835815</td>\n",
       "      <td>-3.859459</td>\n",
       "      <td>-2.993168</td>\n",
       "      <td>1502.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hit_id          x         y       z  volume_id  layer_id  module_id  uID  \\\n",
       "0       1 -64.409897 -7.163700 -1502.5          7         2          1    0   \n",
       "1       2 -55.336102  0.635342 -1502.5          7         2          1    0   \n",
       "2       3 -83.830498 -1.143010 -1502.5          7         2          1    0   \n",
       "3       4 -96.109100 -8.241030 -1502.5          7         2          1    0   \n",
       "4       5 -62.673599 -9.371200 -1502.5          7         2          1    0   \n",
       "\n",
       "         x2        y2         z2         r2            r       eta       phi  \\\n",
       "0 -0.042829 -0.004763 -23.184208  64.807045  1503.896973 -3.837108 -3.030827   \n",
       "1 -0.036804  0.000423 -27.150467  55.339748  1503.518799 -3.994889  3.130112   \n",
       "2 -0.055707 -0.000760 -17.921406  83.838287  1504.837158 -3.579932 -3.127959   \n",
       "3 -0.063835 -0.005474 -15.576118  96.461777  1505.593262 -3.439919 -3.056055   \n",
       "4 -0.041676 -0.006232 -23.709833  63.370335  1503.835815 -3.859459 -2.993168   \n",
       "\n",
       "     absZ  \n",
       "0  1502.5  \n",
       "1  1502.5  \n",
       "2  1502.5  \n",
       "3  1502.5  \n",
       "4  1502.5  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hits_with_uID = pd.merge(hits, hits_pd, on=['volume_id', 'layer_id', 'module_id'])\n",
    "from utils import get_features\n",
    "hits_final = get_features(hits_with_uID)\n",
    "hits_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_truth = truth[ (truth['weight'] > 5e-7 ) & (truth['particle_id'] != 0) ]\n",
    "training = hits_final.merge(filtered_truth, on='hit_id')[['uID', 'particle_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total particles: 9292\n"
     ]
    }
   ],
   "source": [
    "truth_particles = pd.Series(np.unique(training['particle_id']))\n",
    "print(\"total particles:\", truth_particles.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try the RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HitPredictor(nn.Module):\n",
    "    def __init__(self, input_dim=20, hidden_dim=20, output_dim=20,\n",
    "                n_lstm_layers=1):\n",
    "        super(HitPredictor, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.batch_size = 1\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, n_lstm_layers)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return (torch.zeros(self.lstm.num_layers, self.batch_size, self.hidden_dim),\n",
    "                torch.zeros(self.lstm.num_layers, self.batch_size, self.hidden_dim))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output, self.hidden = self.lstm(x, self.hidden)\n",
    "        output = self.fc(output.view(len(x), -1))\n",
    "#         output = self.fc(output)\n",
    "        output = self.dropout(output)\n",
    "        tag_scores = self.softmax(output)\n",
    "        return tag_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
    "        self.o2o = nn.Linear(hidden_size + output_size, output_size)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        input_combined = torch.cat((input, hidden), 1)\n",
    "        hidden = self.i2h(input_combined)\n",
    "        output = self.i2o(input_combined)\n",
    "        output_combined = torch.cat((hidden, output), 1)\n",
    "        output = self.o2o(output_combined)\n",
    "        output = self.dropout(output)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HitPredictorSteve(nn.Module):\n",
    "    \"\"\"RNN which predicts sequence of next-hits from input sequence\"\"\"\n",
    "\n",
    "    def __init__(self, input_dim=3, hidden_dim=5, output_dim=2,\n",
    "                 n_lstm_layers=1):\n",
    "        super(HitPredictor, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, n_lstm_layers,\n",
    "                            batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        input_size = x.size()\n",
    "        # Initialize the lstm hidden state\n",
    "        torch_zeros = torchutils.torch_zeros\n",
    "        func_args = (self.lstm.num_layers, input_size[0], self.lstm.hidden_size)\n",
    "        h = (torch_zeros(*func_args), torch_zeros(*func_args))\n",
    "        x, h = self.lstm(x, h)\n",
    "        # Flatten layer axis into batch axis so FC applies\n",
    "        # independently across layers.\n",
    "        x = (self.fc(x.contiguous().view(-1, x.size(-1)))\n",
    "             .view(input_size[0], input_size[1], -1))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inputHits(series):\n",
    "    tensor = torch.zeros(len(series), 1, total_modules+1)\n",
    "    for idx, h in enumerate(series):\n",
    "        tensor[idx][0][h] = 1\n",
    "\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def targetHits(series):\n",
    "    module_idx = series[1:].tolist()\n",
    "    module_idx.append(total_modules)\n",
    "    return torch.LongTensor(module_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomTrack():\n",
    "    pID = truth_particles.sample(1).values\n",
    "    hit_series = training[training['particle_id'] == pID[0]]['uID'].values\n",
    "    input_tensor = inputHits(hit_series)\n",
    "    target_tensor = targetHits(hit_series)\n",
    "    return input_tensor, target_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getInputTarget(hit_series):\n",
    "    input_tensor = inputHits(hit_series)\n",
    "    target_tensor = targetHits(hit_series)\n",
    "    return input_tensor, target_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 1, 18729])\n",
      "12\n",
      "torch.Size([12])\n"
     ]
    }
   ],
   "source": [
    "input2_, target2_ = randomTrack()\n",
    "print(input2_.size())\n",
    "print(len(input2_))\n",
    "print(target2_.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_result(input_, tags_, target_):\n",
    "    with torch.no_grad():\n",
    "        print(\"inputs:\", torch.reshape(torch.argmax(input_, dim=2), (-1,)))\n",
    "        print(\"predictions:\", torch.argmax(tags_, dim=1))\n",
    "#         print(\"target:\", target_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train RNN with all tracks in this event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 0s (0 0%) 1.2340\n",
      "inputs: tensor([   864,   1197,   1729,   2608,   5376,   6358,   7652,  15401])\n",
      "predictions: tensor([ 10806,   6336,   8989,    783,   6336,   4088,   6336,   6336])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-c7319a5f1cfe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m#         loss += criterion(output, torch.tensor([target_[i]]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rlpy3p6/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rlpy3p6/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     87\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     88\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_iters = truth_particles.shape[0]\n",
    "\n",
    "# n_iters = 20\n",
    "print_every = n_iters/10\n",
    "plot_every = 20\n",
    "all_losses = []\n",
    "total_loss = 0\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "rnn = HitPredictor(input_dim=total_modules+1, hidden_dim=128, \n",
    "                   output_dim=total_modules+1,\n",
    "                   n_lstm_layers=1)\n",
    "optimizer = optim.SGD(rnn.parameters(), lr=0.01)\n",
    "\n",
    "for iter_ in range(n_iters):\n",
    "    pID = truth_particles.values[iter_]\n",
    "\n",
    "    # prepare the inputs\n",
    "    input_, target_ = getInputTarget(training[training['particle_id'] == pID]['uID'].values)\n",
    "    \n",
    "    # training\n",
    "    rnn.zero_grad()\n",
    "    rnn.hidden = rnn.init_hidden()\n",
    "    \n",
    "    loss = 0\n",
    "    \n",
    "    output = rnn(input_)    \n",
    "    loss = criterion(output, target_)\n",
    "\n",
    "#     for i in range(input_.size(0) - 1):\n",
    "#         output = rnn(input_[i].view(1, 1, -1))\n",
    "#         loss += criterion(output, torch.tensor([target_[i]]))\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    normed_loss = loss.item()/input_.size(0)\n",
    "    total_loss += normed_loss\n",
    "    if iter_ % print_every == 0:\n",
    "        print('%s (%d %d%%) %.4f' % (timeSince(start), iter_, iter_ / n_iters * 100, normed_loss))\n",
    "        check_result(input_, output, target_)\n",
    "        \n",
    "    if iter_ % plot_every == 0:\n",
    "        all_losses.append(total_loss / plot_every)\n",
    "        total_loss = 0\n",
    "\n",
    "print(\"I am done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 1, 18729])\n"
     ]
    }
   ],
   "source": [
    "print(output.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(rnn.state_dict(), \"trained_1event_rnn_model_01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([ 18728,  17850,  10663]),\n",
       " tensor([ 18728,  17850,   9660]),\n",
       " tensor([ 18728,   9660,  17850]),\n",
       " tensor([ 18728,   9660,  10663]),\n",
       " tensor([ 18728,   9660,  10663]),\n",
       " tensor([ 18728,  11561,   9660]),\n",
       " tensor([ 18728,  11561,  14304]),\n",
       " tensor([ 18728,  16123,  11561]),\n",
       " tensor([ 18728,  14304,  13833]),\n",
       " tensor([ 18728,  11561,  14304]),\n",
       " tensor([ 18728,  14304,  11561]),\n",
       " tensor([ 18728,  11561,   1428]),\n",
       " tensor([ 18728,  11561,  14304]),\n",
       " tensor([ 18728,  11561,  16123]),\n",
       " tensor([ 18728,  16123,  11561]),\n",
       " tensor([ 18728,  14304,  13833]),\n",
       " tensor([ 18728,  11561,  14304]),\n",
       " tensor([ 18728,  11561,  14304]),\n",
       " tensor([ 18728,  11561,  16123]),\n",
       " tensor([ 18728,  16123,  11561])]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_trainingPredictor(2182)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(1.00000e-02 *\n",
       "        4.9290),\n",
       " tensor(9.8184),\n",
       " tensor(9.7882),\n",
       " tensor(9.7540),\n",
       " tensor(9.7217)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_trainingPredictor(start_hit):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = inputHits([start_hit])\n",
    "        rnn.hidden = rnn.init_hidden()\n",
    "        out_hits = []\n",
    "        pre_can = -1\n",
    "        for i in range(max_nhits):\n",
    "            output = rnn(input_tensor)\n",
    "            topv, topi = output.topk(3)\n",
    "            cand = topi[0][1]\n",
    "#             if cand <= pre_can:\n",
    "#                 break\n",
    "#             else:\n",
    "#                 pre_can = cand\n",
    "            if cand == total_modules:\n",
    "                print(\"Hit the last hits\")\n",
    "                break\n",
    "            else:\n",
    "                out_hits.append(topi[0])\n",
    "            input_tensor = inputHits([cand])\n",
    "        return out_hits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training with RNN\n",
    "example is taken from: [link](https://pytorch.org/tutorials/intermediate/char_rnn_generation_tutorial.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1m 3s (0 0%) 9.8356\n"
     ]
    }
   ],
   "source": [
    "n_iters = truth_particles.shape[0]\n",
    "\n",
    "n_iters = 1000\n",
    "n_iters = truth_particles.shape[0] if n_iters > truth_particles.shape[0] else n_iters\n",
    "print_every = n_iters/10\n",
    "# print_every = 1\n",
    "plot_every = 20\n",
    "all_losses = []\n",
    "total_loss = 0\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "rnn = RNN(total_modules+1, 512, total_modules+1)\n",
    "optimizer = optim.SGD(rnn.parameters(), lr=0.01)\n",
    "\n",
    "for iter_ in range(n_iters):\n",
    "    pID = truth_particles.values[iter_]\n",
    "\n",
    "    # prepare the inputs\n",
    "    input_, target_ = getInputTarget(training[training['particle_id'] == pID]['uID'].values)\n",
    "    \n",
    "    # training\n",
    "    rnn.zero_grad()\n",
    "    hidden = rnn.initHidden()\n",
    "   \n",
    "    loss = 0\n",
    "    for i in range(input_.size(0)):\n",
    "        tag_scores, hidden = rnn(input_[i], hidden)\n",
    "        loss += criterion(tag_scores, torch.tensor([target_[i]]))\n",
    "\n",
    "#     tag_scores, hidden = rnn(input_, hidden)\n",
    "#     loss = criterion(tag_scores, target_)\n",
    "        \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    norm_loss = loss/input_.size(0)\n",
    "    total_loss += norm_loss\n",
    "    if iter_ % print_every == 0:\n",
    "        print('%s (%d %d%%) %.4f' % (timeSince(start), iter_, iter_ / n_iters * 100, norm_loss))\n",
    "#         check_result(input_, tag_scores, target_)\n",
    "        \n",
    "    if iter_ % plot_every == 0:\n",
    "        all_losses.append(total_loss / plot_every)\n",
    "        total_loss = 0\n",
    "\n",
    "print(\"I am done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def check_training(start_hit):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = inputHits([start_hit])\n",
    "        print(input_tensor.size())\n",
    "        print(input_tensor[0][0][start_hit])\n",
    "        rnn.hidden = rnn.init_hidden()\n",
    "        out_hits = []\n",
    "        for i in range(max_nhits):\n",
    "            output = rnn(input_tensor)\n",
    "            topv, topi = output.topk(1)\n",
    "            topi = topi[0][0]\n",
    "            if topi == total_modules:\n",
    "                print(\"Hit the last hits\")\n",
    "                break\n",
    "            else:\n",
    "                out_hits.append(topi)\n",
    "            input_tensor = inputHits([topi])\n",
    "        return out_hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_trainingRNN(start_hit):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = inputHits([start_hit])\n",
    "        hidden = rnn.initHidden()\n",
    "        out_hits = []\n",
    "        topi = start_hit\n",
    "        for i in range(max_nhits):\n",
    "#             print(input_tensor.size())\n",
    "#             print(input_tensor[0][0][topi])\n",
    "            print(topi)\n",
    "            output, hidden = rnn(input_tensor[0], hidden)\n",
    "            # print(output)\n",
    "            # print(output.size())\n",
    "            topv, topi = output.topk(3)\n",
    "#             topi = topi[0][1]\n",
    "            if topi[0][0] == total_modules:\n",
    "                print(\"Hit the last hits\")\n",
    "                break\n",
    "            else:\n",
    "                out_hits.append(topi[0])\n",
    "            topi = topi[0][0]\n",
    "            input_tensor = inputHits([topi])\n",
    "        return out_hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1150\n",
      "tensor(1150)\n",
      "tensor(1150)\n",
      "tensor(1150)\n",
      "tensor(1150)\n",
      "tensor(1150)\n",
      "tensor(1150)\n",
      "tensor(10643)\n",
      "tensor(1150)\n",
      "tensor(1150)\n",
      "tensor(1150)\n",
      "tensor(1150)\n",
      "tensor(1150)\n",
      "tensor(1150)\n",
      "tensor(1150)\n",
      "tensor(10643)\n",
      "tensor(2336)\n",
      "tensor(3348)\n",
      "tensor(12162)\n",
      "tensor(12162)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[tensor([  1150,  10643,   2336]),\n",
       " tensor([  1150,  10643,   2336]),\n",
       " tensor([  1150,  10643,   2336]),\n",
       " tensor([  1150,  10643,   2336]),\n",
       " tensor([  1150,  10643,   2336]),\n",
       " tensor([  1150,  10643,   2336]),\n",
       " tensor([ 10643,   2336,  12162]),\n",
       " tensor([  1150,   2336,  18164]),\n",
       " tensor([  1150,  10643,  12162]),\n",
       " tensor([  1150,  10643,   2336]),\n",
       " tensor([  1150,  10643,   2336]),\n",
       " tensor([  1150,  10643,   2336]),\n",
       " tensor([  1150,  10643,   2336]),\n",
       " tensor([  1150,  10643,   2336]),\n",
       " tensor([ 10643,   2336,  12162]),\n",
       " tensor([  2336,  18164,  12162]),\n",
       " tensor([  3348,  12162,   2336]),\n",
       " tensor([ 12162,   2336,   3453]),\n",
       " tensor([ 12162,   7141,   2336]),\n",
       " tensor([ 12162,   2608,   2336])]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_trainingRNN(1150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(rnn.state_dict(), \"trained_1event_rnn_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(127.8480)\n"
     ]
    }
   ],
   "source": [
    "input_, target = randomTrack()\n",
    "rnn = HitPredictor(input_dim=total_modules+1, hidden_dim=128, output_dim=total_modules+1)\n",
    "\n",
    "#target.unsqueeze_(-1)\n",
    "rnn.hidden = rnn.init_hidden()\n",
    "\n",
    "rnn.zero_grad()\n",
    "loss = 0\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "for i in range(input_.size(0) - 1):\n",
    "    output = rnn(input_[0].view(1, 1, -1))\n",
    "    loss += criterion(output, torch.tensor([target[i]]))\n",
    "    \n",
    "\n",
    "# print(\"input size:\", input_.size())\n",
    "# print('target size:', target.size())\n",
    "# output = rnn(input_)\n",
    "# print(\"output size:\", output.size())\n",
    "# print(target)\n",
    "# loss = criterion(output, target)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_, target = randomTrack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-38-24a2ed7d7105>, line 18)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-38-24a2ed7d7105>\"\u001b[0;36m, line \u001b[0;32m18\u001b[0m\n\u001b[0;31m    print(loss)\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "rnn = RNN(total_modules+1, 3, total_modules+1)\n",
    "\n",
    "#target.unsqueeze_(-1)\n",
    "hidden = rnn.initHidden()\n",
    "\n",
    "rnn.zero_grad()\n",
    "loss = 0\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "print(\"input size:\", input_.size())\n",
    "print('target size:', target.size())\n",
    "output, hidden = rnn(input_[0], hidden)\n",
    "print(\"output size:\", output.size())\n",
    "print(target)\n",
    "print(target[0])\n",
    "loss = criterion(output, torch.tensor([target[0]]))\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1\n"
     ]
    }
   ],
   "source": [
    "print(output.size(0), torch.tensor([target[0]]).size(0))\n",
    "loss = criterion(output, torch.tensor([target[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1])\n",
      "torch.FloatTensor\n",
      "torch.float32\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-a5513195d698>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mh0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mc0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mh0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/global/project/projectdirs/m1092/xju/miniconda3/envs/py3.6/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/global/project/projectdirs/m1092/xju/miniconda3/envs/py3.6/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0mbatch_sizes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             \u001b[0mmax_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_first\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "rnn2 = nn.LSTM(6, 20)\n",
    "input = torch.randn(1)\n",
    "print(input.size())\n",
    "print(input.type())\n",
    "print(input.dtype)\n",
    "h0 = torch.randn(2, 1, 20)\n",
    "c0 = torch.randn(2, 1, 20)\n",
    "output, hn = rnn2(input, (h0, c0))\n",
    "print(output)\n",
    "print(output.size())\n",
    "print(hn)\n",
    "print(hn[0].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.LogSoftmax(dim=1)\n",
    "loss = nn.NLLLoss()\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.tensor([1, 0, 4])\n",
    "print(target.size())\n",
    "print(m(input).size())\n",
    "output = loss(m(input), target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1,  2,  4,  5])\n"
     ]
    }
   ],
   "source": [
    "embedding = nn.Embedding(10, 3)\n",
    "input = torch.LongTensor([1,2,4,5])\n",
    "print(input)\n",
    "embeds = embedding(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3])\n",
      "torch.Size([4])\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "print(embeds.size())\n",
    "print(input.size())\n",
    "print(len(input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5956, -0.3846,  0.6718],\n",
      "        [ 0.4788,  0.3929,  0.4087],\n",
      "        [ 0.3090,  0.4232,  1.3487],\n",
      "        [ 2.1231, -0.9157, -1.3121]])\n",
      "tensor([[[-0.5956, -0.3846,  0.6718]],\n",
      "\n",
      "        [[ 0.4788,  0.3929,  0.4087]],\n",
      "\n",
      "        [[ 0.3090,  0.4232,  1.3487]],\n",
      "\n",
      "        [[ 2.1231, -0.9157, -1.3121]]])\n",
      "torch.Size([4, 1, 3])\n"
     ]
    }
   ],
   "source": [
    "print(embeds)\n",
    "new_embeds = embeds.view(len(input), 1, -1)\n",
    "print(new_embeds)\n",
    "print(new_embeds.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
