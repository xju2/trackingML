{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trackml.dataset import load_event\n",
    "from trackml.randomize import shuffle_hits\n",
    "from trackml.score import score_event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18728\n"
     ]
    }
   ],
   "source": [
    "from utils import make_uID\n",
    "det = pd.read_csv('input/detectors.csv')\n",
    "det.head()\n",
    "hits_pd = make_uID(det)\n",
    "total_modules = hits_pd.shape[0]\n",
    "print(total_modules)\n",
    "max_nhits = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load one event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_prefix = 'event000001000'\n",
    "hits, cells, particles, truth = load_event(os.path.join('input/train_1', event_prefix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hit_id</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>volume_id</th>\n",
       "      <th>layer_id</th>\n",
       "      <th>module_id</th>\n",
       "      <th>uID</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>z2</th>\n",
       "      <th>r2</th>\n",
       "      <th>r</th>\n",
       "      <th>eta</th>\n",
       "      <th>phi</th>\n",
       "      <th>absZ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-64.409897</td>\n",
       "      <td>-7.163700</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.042829</td>\n",
       "      <td>-0.004763</td>\n",
       "      <td>-23.184208</td>\n",
       "      <td>64.807045</td>\n",
       "      <td>1503.896973</td>\n",
       "      <td>-3.837108</td>\n",
       "      <td>-3.030827</td>\n",
       "      <td>1502.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-55.336102</td>\n",
       "      <td>0.635342</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.036804</td>\n",
       "      <td>0.000423</td>\n",
       "      <td>-27.150467</td>\n",
       "      <td>55.339748</td>\n",
       "      <td>1503.518799</td>\n",
       "      <td>-3.994889</td>\n",
       "      <td>3.130112</td>\n",
       "      <td>1502.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>-83.830498</td>\n",
       "      <td>-1.143010</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.055707</td>\n",
       "      <td>-0.000760</td>\n",
       "      <td>-17.921406</td>\n",
       "      <td>83.838287</td>\n",
       "      <td>1504.837158</td>\n",
       "      <td>-3.579932</td>\n",
       "      <td>-3.127959</td>\n",
       "      <td>1502.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>-96.109100</td>\n",
       "      <td>-8.241030</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.063835</td>\n",
       "      <td>-0.005474</td>\n",
       "      <td>-15.576118</td>\n",
       "      <td>96.461777</td>\n",
       "      <td>1505.593262</td>\n",
       "      <td>-3.439919</td>\n",
       "      <td>-3.056055</td>\n",
       "      <td>1502.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>-62.673599</td>\n",
       "      <td>-9.371200</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.041676</td>\n",
       "      <td>-0.006232</td>\n",
       "      <td>-23.709833</td>\n",
       "      <td>63.370335</td>\n",
       "      <td>1503.835815</td>\n",
       "      <td>-3.859459</td>\n",
       "      <td>-2.993168</td>\n",
       "      <td>1502.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hit_id          x         y       z  volume_id  layer_id  module_id  uID  \\\n",
       "0       1 -64.409897 -7.163700 -1502.5          7         2          1    0   \n",
       "1       2 -55.336102  0.635342 -1502.5          7         2          1    0   \n",
       "2       3 -83.830498 -1.143010 -1502.5          7         2          1    0   \n",
       "3       4 -96.109100 -8.241030 -1502.5          7         2          1    0   \n",
       "4       5 -62.673599 -9.371200 -1502.5          7         2          1    0   \n",
       "\n",
       "         x2        y2         z2         r2            r       eta       phi  \\\n",
       "0 -0.042829 -0.004763 -23.184208  64.807045  1503.896973 -3.837108 -3.030827   \n",
       "1 -0.036804  0.000423 -27.150467  55.339748  1503.518799 -3.994889  3.130112   \n",
       "2 -0.055707 -0.000760 -17.921406  83.838287  1504.837158 -3.579932 -3.127959   \n",
       "3 -0.063835 -0.005474 -15.576118  96.461777  1505.593262 -3.439919 -3.056055   \n",
       "4 -0.041676 -0.006232 -23.709833  63.370335  1503.835815 -3.859459 -2.993168   \n",
       "\n",
       "     absZ  \n",
       "0  1502.5  \n",
       "1  1502.5  \n",
       "2  1502.5  \n",
       "3  1502.5  \n",
       "4  1502.5  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hits_with_uID = pd.merge(hits, hits_pd, on=['volume_id', 'layer_id', 'module_id'])\n",
    "from utils import get_features\n",
    "hits_final = get_features(hits_with_uID)\n",
    "hits_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_truth = truth[ (truth['weight'] > 5e-7 ) & (truth['particle_id'] != 0) ]\n",
    "training = hits_final.merge(filtered_truth, on='hit_id')[['uID', 'particle_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total particles: 9292\n"
     ]
    }
   ],
   "source": [
    "truth_particles = pd.Series(np.unique(training['particle_id']))\n",
    "print(\"total particles:\", truth_particles.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try the RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HitPredictor(nn.Module):\n",
    "    def __init__(self, input_dim=20, hidden_dim=20, output_dim=20,\n",
    "                n_lstm_layers=1):\n",
    "        super(HitPredictor, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.batch_size = 1\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, n_lstm_layers)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return (torch.zeros(self.lstm.num_layers, self.batch_size, self.hidden_dim),\n",
    "                torch.zeros(self.lstm.num_layers, self.batch_size, self.hidden_dim))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output, self.hidden = self.lstm(x, self.hidden)\n",
    "        output = self.fc(output.view(len(x), -1))\n",
    "#         output = self.fc(output)\n",
    "        output = self.dropout(output)\n",
    "        tag_scores = self.softmax(output)\n",
    "        return tag_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
    "        self.o2o = nn.Linear(hidden_size + output_size, output_size)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        input_combined = torch.cat((input, hidden), 1)\n",
    "        hidden = self.i2h(input_combined)\n",
    "        output = self.i2o(input_combined)\n",
    "        output_combined = torch.cat((hidden, output), 1)\n",
    "        output = self.o2o(output_combined)\n",
    "        output = self.dropout(output)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HitPredictorSteve(nn.Module):\n",
    "    \"\"\"RNN which predicts sequence of next-hits from input sequence\"\"\"\n",
    "\n",
    "    def __init__(self, input_dim=3, hidden_dim=5, output_dim=2,\n",
    "                 n_lstm_layers=1):\n",
    "        super(HitPredictor, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, n_lstm_layers,\n",
    "                            batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        input_size = x.size()\n",
    "        # Initialize the lstm hidden state\n",
    "        torch_zeros = torchutils.torch_zeros\n",
    "        func_args = (self.lstm.num_layers, input_size[0], self.lstm.hidden_size)\n",
    "        h = (torch_zeros(*func_args), torch_zeros(*func_args))\n",
    "        x, h = self.lstm(x, h)\n",
    "        # Flatten layer axis into batch axis so FC applies\n",
    "        # independently across layers.\n",
    "        x = (self.fc(x.contiguous().view(-1, x.size(-1)))\n",
    "             .view(input_size[0], input_size[1], -1))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inputHits(series):\n",
    "    tensor = torch.zeros(len(series), 1, total_modules+1)\n",
    "    for idx, h in enumerate(series):\n",
    "        tensor[idx][0][h] = 1\n",
    "\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def targetHits(series):\n",
    "    module_idx = series[1:].tolist()\n",
    "    module_idx.append(total_modules)\n",
    "    return torch.LongTensor(module_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomTrack():\n",
    "    pID = truth_particles.sample(1).values\n",
    "    hit_series = training[training['particle_id'] == pID[0]]['uID'].values\n",
    "    input_tensor = inputHits(hit_series)\n",
    "    target_tensor = targetHits(hit_series)\n",
    "    return input_tensor, target_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getInputTarget(hit_series):\n",
    "    input_tensor = inputHits(hit_series)\n",
    "    target_tensor = targetHits(hit_series)\n",
    "    return input_tensor, target_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 1, 18729])\n",
      "12\n",
      "torch.Size([12])\n"
     ]
    }
   ],
   "source": [
    "input2_, target2_ = randomTrack()\n",
    "print(input2_.size())\n",
    "print(len(input2_))\n",
    "print(target2_.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_result(input_, tags_, target_):\n",
    "    with torch.no_grad():\n",
    "        print(\"inputs:\", torch.reshape(torch.argmax(input_, dim=2), (-1,)))\n",
    "        print(\"predictions:\", torch.argmax(tags_, dim=1))\n",
    "#         print(\"target:\", target_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tunable_parameters(model):\n",
    "    model_parameters = filter(lambda p:p.requires_grad, model.parameters())\n",
    "#     for p in model_parameters:\n",
    "#         print(p.size())\n",
    "    params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total parameters: 1893389\n"
     ]
    }
   ],
   "source": [
    "rnn = HitPredictor(input_dim=total_modules+1, hidden_dim=20, \n",
    "                   output_dim=total_modules+1,\n",
    "                   n_lstm_layers=1)\n",
    "print(\"total parameters:\", tunable_parameters(rnn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'dampening': 0,\n",
       "  'lr': 0.01,\n",
       "  'momentum': 0,\n",
       "  'nesterov': False,\n",
       "  'params': [Parameter containing:\n",
       "   tensor([[-6.9197e-03,  1.2506e-02, -7.3080e-02,  ..., -8.8995e-03,\n",
       "            -4.4424e-02,  7.9154e-02],\n",
       "           [-5.4895e-02, -1.7606e-02,  6.7705e-02,  ..., -5.7081e-02,\n",
       "            -7.0979e-02,  6.1764e-02],\n",
       "           [ 5.5128e-02, -8.4866e-02,  2.9523e-02,  ...,  7.3421e-02,\n",
       "            -3.5992e-02,  2.7184e-03],\n",
       "           ...,\n",
       "           [-4.3446e-02, -6.3897e-02,  1.1159e-02,  ..., -1.4577e-02,\n",
       "             6.4728e-02,  2.3673e-02],\n",
       "           [ 5.3200e-02, -5.5853e-02, -4.8760e-02,  ...,  7.3623e-02,\n",
       "            -7.1024e-02,  5.9435e-02],\n",
       "           [ 3.5973e-03, -3.6972e-02, -7.7954e-03,  ...,  6.5545e-02,\n",
       "            -9.4303e-03,  1.8172e-03]]), Parameter containing:\n",
       "   tensor([[-5.5579e-02,  3.6240e-03, -6.8016e-02,  ..., -6.7853e-02,\n",
       "             1.1284e-02, -5.4729e-02],\n",
       "           [-2.0092e-02,  2.4411e-02,  6.2843e-02,  ..., -3.7107e-02,\n",
       "            -6.8741e-02,  3.2151e-02],\n",
       "           [-3.1032e-02,  5.0676e-02,  6.1629e-03,  ...,  2.3711e-02,\n",
       "            -2.9909e-02, -3.3990e-02],\n",
       "           ...,\n",
       "           [ 4.8306e-02, -7.8361e-02, -1.3810e-02,  ...,  5.1927e-02,\n",
       "             4.2737e-03,  7.2499e-02],\n",
       "           [ 6.8611e-02,  3.7486e-02,  6.0021e-02,  ...,  7.1415e-03,\n",
       "            -4.4022e-02,  3.6047e-02],\n",
       "           [-4.5588e-02,  4.0364e-02,  6.1294e-03,  ..., -4.2571e-02,\n",
       "            -3.9276e-02,  4.7123e-02]]), Parameter containing:\n",
       "   tensor([-0.0055, -0.0385,  0.0056,  0.0872,  0.0555, -0.0403,  0.0560,\n",
       "            0.0662, -0.0109, -0.0704, -0.0130, -0.0579,  0.0312,  0.0656,\n",
       "           -0.0669, -0.0426,  0.0319,  0.0676, -0.0083, -0.0442, -0.0288,\n",
       "           -0.0380,  0.0638,  0.0294,  0.0285, -0.0245,  0.0809,  0.0491,\n",
       "           -0.0634,  0.0020,  0.0709, -0.0149,  0.0504, -0.0589, -0.0154,\n",
       "           -0.0548, -0.0851, -0.0207, -0.0003, -0.0658, -0.0101,  0.0699,\n",
       "            0.0342, -0.0083,  0.0586,  0.0481, -0.0714,  0.0306,  0.0797,\n",
       "            0.0147, -0.0079, -0.0456,  0.0600, -0.0663,  0.0538,  0.0745,\n",
       "            0.0220,  0.1293,  0.0624,  0.0968,  0.0418, -0.0276,  0.0257,\n",
       "           -0.0143,  0.0863, -0.0104, -0.0375, -0.0680,  0.0948, -0.0439,\n",
       "           -0.0442,  0.0782, -0.0156,  0.0253, -0.0727,  0.0547,  0.0879,\n",
       "           -0.0885,  0.0748,  0.0817, -0.0343,  0.0358,  0.0679, -0.0162,\n",
       "           -0.0768,  0.1052,  0.0475, -0.0185, -0.0086, -0.0514, -0.0047,\n",
       "           -0.0325, -0.0568,  0.0825,  0.0942, -0.0113,  0.0026, -0.0240,\n",
       "           -0.0754,  0.0245,  0.0019,  0.0422,  0.0205, -0.0024, -0.0246,\n",
       "           -0.0538,  0.0023,  0.0312, -0.0611,  0.0565,  0.0059,  0.0124,\n",
       "           -0.0647,  0.0102,  0.0657,  0.0221,  0.0466, -0.0454, -0.0140,\n",
       "            0.0604, -0.0477, -0.0746,  0.0562, -0.0628, -0.0578, -0.0801,\n",
       "            0.0018,  0.0149,  0.0412, -0.0017,  0.0961, -0.0324,  0.0433,\n",
       "            0.0224,  0.0206, -0.0137,  0.0799, -0.0007,  0.0225,  0.0839,\n",
       "            0.0186,  0.1180, -0.0205,  0.0914, -0.0453, -0.0424,  0.0005,\n",
       "           -0.0361, -0.0655, -0.0509, -0.0365, -0.0012,  0.0426,  0.0881,\n",
       "            0.0204, -0.0313, -0.0542, -0.0022,  0.1230, -0.0324, -0.0610,\n",
       "            0.1037,  0.0150, -0.0386, -0.0495,  0.0067, -0.0790, -0.0319,\n",
       "           -0.0448,  0.0950,  0.0508,  0.0775,  0.0287, -0.0391, -0.0028,\n",
       "           -0.0740,  0.0100, -0.0290,  0.0470, -0.0518,  0.0997,  0.0406,\n",
       "            0.0441, -0.0115,  0.0735,  0.0944,  0.0255,  0.0623,  0.0507,\n",
       "           -0.0076, -0.0008,  0.0615,  0.0924,  0.0712, -0.0692, -0.0428,\n",
       "           -0.0539,  0.0076,  0.0360,  0.0775,  0.0883,  0.0040,  0.0453,\n",
       "           -0.0242, -0.0657,  0.0230,  0.0388,  0.0836,  0.0491,  0.1001,\n",
       "            0.0033,  0.0664, -0.0048,  0.0826, -0.0011,  0.0552,  0.0202,\n",
       "            0.0515, -0.0524,  0.0826,  0.0894,  0.0051, -0.0235,  0.0161,\n",
       "           -0.0028,  0.0474,  0.0127,  0.0133,  0.0544, -0.0109,  0.0788,\n",
       "            0.0583,  0.0071, -0.0223, -0.0376,  0.0684,  0.0814, -0.0740,\n",
       "            0.0764,  0.0243, -0.0534, -0.0425,  0.0015,  0.0758,  0.0102,\n",
       "            0.0139,  0.0900,  0.0265,  0.0878,  0.0538,  0.0826, -0.0333,\n",
       "           -0.0674,  0.0273,  0.0773, -0.0562, -0.0556,  0.0927,  0.0458,\n",
       "           -0.1607,  0.0423,  0.1433, -0.1030, -0.1659, -0.0370, -0.1004,\n",
       "            0.0954,  0.0902, -0.0165,  0.2476, -0.0317,  0.2011, -0.0592,\n",
       "           -0.0625, -0.1051, -0.0696,  0.1552,  0.1409, -0.1571, -0.0963,\n",
       "           -0.0773,  0.0435, -0.0241, -0.1053,  0.1470, -0.1249,  0.2193,\n",
       "            0.0367, -0.1499, -0.1659,  0.0162,  0.0713, -0.1402, -0.1264,\n",
       "            0.0200,  0.1432, -0.0980,  0.2478, -0.0970, -0.1303,  0.0236,\n",
       "           -0.0187, -0.0126,  0.0378, -0.0822, -0.0031,  0.1333, -0.0685,\n",
       "            0.1727,  0.0814, -0.0654, -0.0962,  0.0168,  0.2318,  0.0034,\n",
       "            0.1461,  0.1661,  0.1677, -0.1338,  0.0884, -0.1788,  0.0456,\n",
       "            0.1799,  0.1089,  0.0994, -0.0218,  0.0522, -0.1906,  0.0724,\n",
       "            0.0999, -0.0473, -0.0460,  0.1497, -0.0752, -0.0273, -0.0219,\n",
       "           -0.0832,  0.1512, -0.0995, -0.1276, -0.1509, -0.2054, -0.0096,\n",
       "            0.0076, -0.0227, -0.1866, -0.1451,  0.0338, -0.0561,  0.0624,\n",
       "            0.1184,  0.1793,  0.0731, -0.1337, -0.0137,  0.0904,  0.0601,\n",
       "            0.1805,  0.1238, -0.1960, -0.0980, -0.0198, -0.1830, -0.2377,\n",
       "            0.0135, -0.0180, -0.2105, -0.0376, -0.1364,  0.1753, -0.1524,\n",
       "           -0.1027,  0.0380,  0.1801,  0.0837,  0.0249, -0.1141,  0.0390,\n",
       "            0.0155, -0.0484,  0.1122,  0.0353, -0.1796, -0.0075, -0.0783,\n",
       "            0.0760,  0.0569, -0.0061, -0.0067,  0.0825,  0.0094,  0.0870,\n",
       "            0.0798, -0.0310,  0.0455,  0.1146, -0.0163, -0.0073,  0.0749,\n",
       "            0.0291, -0.0414,  0.0955,  0.0376, -0.0480,  0.0649, -0.0716,\n",
       "           -0.0008,  0.0227,  0.0470, -0.0632, -0.0653, -0.0645, -0.0142,\n",
       "            0.0836,  0.1286,  0.0110,  0.0776,  0.0353,  0.0362,  0.0442,\n",
       "           -0.0735,  0.0345,  0.0076, -0.0635,  0.0045,  0.0913,  0.0121,\n",
       "           -0.0369, -0.0809,  0.0708,  0.0813,  0.0513, -0.0785, -0.0499,\n",
       "           -0.0303, -0.0528, -0.0104,  0.0060,  0.0193,  0.0809, -0.0491,\n",
       "            0.0885,  0.0612,  0.0308, -0.0305,  0.0862,  0.0540,  0.0102,\n",
       "           -0.0086, -0.0264, -0.0334, -0.0613, -0.0751,  0.0093, -0.0312,\n",
       "            0.0158, -0.0770, -0.0358,  0.0604, -0.0509, -0.0103, -0.0463,\n",
       "           -0.0709,  0.0472, -0.0758, -0.0194, -0.0762,  0.0704, -0.0656,\n",
       "            0.0750, -0.0322, -0.0172,  0.0680,  0.0810,  0.0519, -0.0522,\n",
       "           -0.0726, -0.0382,  0.0075,  0.0306, -0.0534,  0.0366, -0.0761,\n",
       "            0.0473, -0.0794, -0.0586,  0.0256,  0.0624,  0.0758,  0.0637,\n",
       "           -0.0245,  0.0371, -0.0741, -0.0122, -0.0221,  0.0336,  0.1078,\n",
       "            0.0385,  0.0369,  0.0106, -0.0149,  0.0002, -0.0027, -0.0461,\n",
       "            0.0016,  0.0176,  0.0302,  0.0691, -0.0700,  0.0218, -0.0508,\n",
       "           -0.0807]), Parameter containing:\n",
       "   tensor([ 0.0367, -0.0425,  0.0219, -0.0696,  0.0282, -0.0639,  0.0190,\n",
       "           -0.0219, -0.0044, -0.0072,  0.0216, -0.0204, -0.0010,  0.0044,\n",
       "           -0.0523,  0.0969,  0.0074, -0.0524,  0.0924, -0.0228,  0.0245,\n",
       "            0.0080, -0.0684, -0.0872, -0.0169, -0.0822, -0.0689,  0.0689,\n",
       "           -0.0577,  0.0542,  0.0102, -0.0265, -0.0136, -0.0183,  0.0296,\n",
       "            0.0133,  0.0319, -0.0480, -0.0354,  0.0034,  0.0045,  0.0398,\n",
       "           -0.0072, -0.0112, -0.0483,  0.0095,  0.0017, -0.0667,  0.0000,\n",
       "           -0.0123,  0.0420,  0.0554,  0.0859,  0.0624, -0.0290, -0.0770,\n",
       "           -0.0617,  0.1235,  0.0389,  0.0668,  0.0311, -0.0634, -0.0576,\n",
       "            0.0581,  0.0686, -0.0466,  0.0798,  0.0045, -0.0181, -0.0282,\n",
       "            0.0805,  0.0520, -0.0593, -0.0493, -0.0255, -0.0391, -0.0171,\n",
       "           -0.0418, -0.0427,  0.0295,  0.0406,  0.0756, -0.0379, -0.0639,\n",
       "           -0.0266, -0.0218,  0.0622,  0.0010, -0.0691,  0.0826,  0.0599,\n",
       "           -0.0753,  0.0018,  0.0594,  0.0742,  0.0736, -0.0664, -0.0689,\n",
       "            0.0106,  0.0927,  0.0846,  0.0518, -0.0376,  0.0851,  0.0396,\n",
       "            0.0683,  0.0585, -0.0348, -0.0251, -0.0487, -0.0500, -0.0158,\n",
       "            0.0389,  0.0822, -0.0405,  0.0360, -0.0595,  0.0921, -0.0058,\n",
       "            0.0454, -0.0282, -0.0797,  0.0733,  0.0904, -0.0606,  0.0597,\n",
       "           -0.0213,  0.0190,  0.0299,  0.0930,  0.0269, -0.0526, -0.0053,\n",
       "           -0.0606,  0.0533,  0.0771, -0.0605,  0.0279, -0.0240,  0.0614,\n",
       "           -0.0612,  0.0680, -0.0693,  0.0769, -0.0192, -0.0247,  0.0755,\n",
       "           -0.0363,  0.0705,  0.0051, -0.0292, -0.0825, -0.0058, -0.0334,\n",
       "            0.0559, -0.0780,  0.0716,  0.0387,  0.0471, -0.0331, -0.0387,\n",
       "            0.0799,  0.0413, -0.0518,  0.0703,  0.0119, -0.0711,  0.0084,\n",
       "           -0.0408,  0.0523,  0.0153,  0.0023, -0.0306, -0.0836,  0.0156,\n",
       "            0.0147,  0.0870, -0.0166,  0.0978, -0.0515, -0.0358, -0.0449,\n",
       "           -0.0002, -0.0298,  0.0001,  0.0376, -0.0088,  0.0105, -0.0186,\n",
       "            0.1088, -0.0390, -0.0229, -0.0294, -0.0792, -0.0284,  0.0981,\n",
       "            0.0878,  0.0343,  0.0498, -0.0386,  0.0859,  0.0652, -0.0843,\n",
       "            0.0072,  0.0891,  0.0749,  0.0686, -0.0558,  0.0395, -0.0002,\n",
       "           -0.0146,  0.0784, -0.0477,  0.0660, -0.0065,  0.0616,  0.0431,\n",
       "            0.0900,  0.0962,  0.0996, -0.0565,  0.0340, -0.0499,  0.0460,\n",
       "           -0.0095,  0.0615, -0.0588,  0.0501, -0.0128, -0.0346, -0.0777,\n",
       "           -0.0144,  0.0327,  0.0684, -0.0261, -0.0388, -0.0444, -0.0576,\n",
       "            0.0757, -0.0666,  0.0816, -0.0588, -0.0716,  0.1037, -0.0293,\n",
       "           -0.0134,  0.0116,  0.0626,  0.0502, -0.0166, -0.0552, -0.0098,\n",
       "            0.0665,  0.0801,  0.0517, -0.0555, -0.0090,  0.0918,  0.1895,\n",
       "           -0.0446, -0.1010,  0.1165, -0.0584,  0.0078, -0.0292, -0.0627,\n",
       "            0.0109,  0.1239, -0.1556,  0.2545, -0.0991,  0.1772,  0.0681,\n",
       "           -0.1046, -0.1100, -0.1123,  0.1712,  0.1209, -0.1034,  0.0266,\n",
       "            0.0140,  0.1169,  0.0280, -0.0262,  0.1711, -0.1503,  0.1858,\n",
       "            0.1363, -0.1481, -0.1424,  0.0023, -0.0217,  0.0070, -0.1217,\n",
       "            0.0522,  0.0570, -0.1098,  0.1780, -0.0762, -0.0535, -0.0911,\n",
       "            0.0665, -0.0272,  0.0681, -0.0141,  0.0278,  0.1846, -0.1034,\n",
       "            0.0621, -0.0463, -0.0767, -0.0744, -0.0406,  0.2281, -0.0464,\n",
       "            0.0622,  0.0313,  0.0342, -0.0156,  0.0404, -0.2377,  0.1301,\n",
       "            0.0975,  0.1065,  0.1243,  0.0504,  0.1502, -0.1295,  0.1363,\n",
       "            0.0242, -0.0689,  0.0883,  0.0647,  0.0348,  0.0376, -0.1472,\n",
       "           -0.1100,  0.1669, -0.0088, -0.1503, -0.0439, -0.0803, -0.0886,\n",
       "           -0.0400,  0.0253, -0.1454, -0.1475,  0.1005, -0.0612,  0.0921,\n",
       "            0.1107,  0.0538, -0.0157,  0.0093,  0.0946,  0.0762,  0.0438,\n",
       "            0.0973,  0.0253, -0.2036, -0.1020, -0.0256, -0.1298, -0.1498,\n",
       "            0.0313, -0.1329, -0.1632,  0.1080, -0.1576,  0.0819, -0.1092,\n",
       "           -0.2187,  0.0445,  0.0934,  0.0769, -0.0988, -0.0717, -0.0244,\n",
       "            0.0197, -0.1667,  0.1038,  0.0038, -0.0864,  0.0624,  0.0002,\n",
       "           -0.0518,  0.0647, -0.0612, -0.0843, -0.0496,  0.0485,  0.0275,\n",
       "            0.0287, -0.0232,  0.0228,  0.0644,  0.0239,  0.0641,  0.0322,\n",
       "            0.0584, -0.0691,  0.0613, -0.0475,  0.0207,  0.0185,  0.0955,\n",
       "            0.0316, -0.0052, -0.0423, -0.0807,  0.0768,  0.0597,  0.0749,\n",
       "            0.0876,  0.0749, -0.0151,  0.0625,  0.0166,  0.0376, -0.0598,\n",
       "            0.0751, -0.0713, -0.0332, -0.0534, -0.0124,  0.0523, -0.0350,\n",
       "           -0.0723, -0.0439,  0.0268,  0.0107, -0.0822, -0.0383,  0.0017,\n",
       "            0.1244,  0.0123,  0.0446, -0.0709, -0.0046,  0.0377, -0.0113,\n",
       "            0.1365, -0.0188,  0.1095,  0.0316, -0.0489, -0.0783, -0.0223,\n",
       "            0.0823,  0.0696, -0.0530,  0.0099,  0.0287,  0.0210,  0.0703,\n",
       "            0.0090, -0.0449,  0.0704,  0.0061, -0.0046,  0.0703, -0.0107,\n",
       "           -0.0353,  0.0754,  0.0955, -0.0509,  0.0341,  0.0972, -0.0035,\n",
       "            0.0189,  0.0676, -0.0040,  0.0445, -0.0127,  0.0488,  0.0213,\n",
       "           -0.0561,  0.0190, -0.0113,  0.0728, -0.0312, -0.0007,  0.0638,\n",
       "            0.0313,  0.0599, -0.0391, -0.0110,  0.0415, -0.0522,  0.0611,\n",
       "           -0.0072, -0.0488, -0.0541,  0.0509,  0.0479, -0.0723,  0.1034,\n",
       "            0.0514,  0.0056, -0.0056, -0.0248, -0.0305,  0.0167, -0.0799,\n",
       "            0.0427, -0.0580, -0.0173,  0.0596, -0.0702, -0.0598, -0.0388,\n",
       "           -0.0071]), Parameter containing:\n",
       "   tensor([[ 7.1830e-02,  1.1255e-02, -6.6971e-02,  ...,  4.0590e-02,\n",
       "             4.9740e-02,  8.7692e-02],\n",
       "           [ 4.3107e-02,  1.6339e-02, -4.7725e-02,  ..., -1.8512e-02,\n",
       "            -5.6290e-02, -5.9291e-03],\n",
       "           [-8.6870e-02, -4.3284e-02, -4.2736e-02,  ..., -7.0017e-02,\n",
       "             4.2632e-03,  8.7194e-05],\n",
       "           ...,\n",
       "           [-4.6145e-02, -6.0920e-02, -8.2773e-02,  ..., -5.4856e-02,\n",
       "             8.2410e-02,  3.7154e-02],\n",
       "           [ 5.3383e-02, -6.0157e-02, -3.0978e-03,  ...,  8.4054e-02,\n",
       "             2.4208e-02, -6.2552e-02],\n",
       "           [-1.1319e-01,  1.2200e-01,  1.2192e-01,  ..., -9.8945e-02,\n",
       "            -2.2833e-01,  1.1561e-01]]), Parameter containing:\n",
       "   tensor([-2.3588e-02, -4.2397e-02,  3.4310e-02,  ...,  8.4744e-02,\n",
       "            1.3450e-02,  1.9737e+00])],\n",
       "  'weight_decay': 0}]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.param_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total parameters: 2362554\n"
     ]
    }
   ],
   "source": [
    "rnn = HitPredictor(input_dim=total_modules+1, hidden_dim=25, \n",
    "                   output_dim=total_modules+1,\n",
    "                   n_lstm_layers=1)\n",
    "print(\"total parameters:\", tunable_parameters(rnn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total parameters: 12203945\n"
     ]
    }
   ],
   "source": [
    "rnn = HitPredictor(input_dim=total_modules+1, hidden_dim=128, \n",
    "                   output_dim=total_modules+1,\n",
    "                   n_lstm_layers=2)\n",
    "print(\"total parameters:\", tunable_parameters(rnn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total parameters: 17859\n"
     ]
    }
   ],
   "source": [
    "rnn = HitPredictor(input_dim=3, hidden_dim=64, \n",
    "                   output_dim=3,\n",
    "                   n_lstm_layers=1)\n",
    "print(\"total parameters:\", tunable_parameters(rnn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train RNN with all tracks in this event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 0s (0 0%) 1.2340\n",
      "inputs: tensor([   864,   1197,   1729,   2608,   5376,   6358,   7652,  15401])\n",
      "predictions: tensor([ 10806,   6336,   8989,    783,   6336,   4088,   6336,   6336])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-c7319a5f1cfe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m#         loss += criterion(output, torch.tensor([target_[i]]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rlpy3p6/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rlpy3p6/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     87\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     88\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_iters = truth_particles.shape[0]\n",
    "\n",
    "# n_iters = 20\n",
    "print_every = n_iters/10\n",
    "plot_every = 20\n",
    "all_losses = []\n",
    "total_loss = 0\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "rnn = HitPredictor(input_dim=total_modules+1, hidden_dim=128, \n",
    "                   output_dim=total_modules+1,\n",
    "                   n_lstm_layers=1)\n",
    "optimizer = optim.SGD(rnn.parameters(), lr=0.01)\n",
    "\n",
    "for iter_ in range(n_iters):\n",
    "    pID = truth_particles.values[iter_]\n",
    "\n",
    "    # prepare the inputs\n",
    "    input_, target_ = getInputTarget(training[training['particle_id'] == pID]['uID'].values)\n",
    "    \n",
    "    # training\n",
    "    rnn.zero_grad()\n",
    "    rnn.hidden = rnn.init_hidden()\n",
    "    \n",
    "    loss = 0\n",
    "    \n",
    "    output = rnn(input_)    \n",
    "    loss = criterion(output, target_)\n",
    "\n",
    "#     for i in range(input_.size(0) - 1):\n",
    "#         output = rnn(input_[i].view(1, 1, -1))\n",
    "#         loss += criterion(output, torch.tensor([target_[i]]))\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    normed_loss = loss.item()/input_.size(0)\n",
    "    total_loss += normed_loss\n",
    "    if iter_ % print_every == 0:\n",
    "        print('%s (%d %d%%) %.4f' % (timeSince(start), iter_, iter_ / n_iters * 100, normed_loss))\n",
    "        check_result(input_, output, target_)\n",
    "        \n",
    "    if iter_ % plot_every == 0:\n",
    "        all_losses.append(total_loss / plot_every)\n",
    "        total_loss = 0\n",
    "\n",
    "print(\"I am done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 1, 18729])\n"
     ]
    }
   ],
   "source": [
    "print(output.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(rnn.state_dict(), \"trained_1event_rnn_model_01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([ 18728,  17850,  10663]),\n",
       " tensor([ 18728,  17850,   9660]),\n",
       " tensor([ 18728,   9660,  17850]),\n",
       " tensor([ 18728,   9660,  10663]),\n",
       " tensor([ 18728,   9660,  10663]),\n",
       " tensor([ 18728,  11561,   9660]),\n",
       " tensor([ 18728,  11561,  14304]),\n",
       " tensor([ 18728,  16123,  11561]),\n",
       " tensor([ 18728,  14304,  13833]),\n",
       " tensor([ 18728,  11561,  14304]),\n",
       " tensor([ 18728,  14304,  11561]),\n",
       " tensor([ 18728,  11561,   1428]),\n",
       " tensor([ 18728,  11561,  14304]),\n",
       " tensor([ 18728,  11561,  16123]),\n",
       " tensor([ 18728,  16123,  11561]),\n",
       " tensor([ 18728,  14304,  13833]),\n",
       " tensor([ 18728,  11561,  14304]),\n",
       " tensor([ 18728,  11561,  14304]),\n",
       " tensor([ 18728,  11561,  16123]),\n",
       " tensor([ 18728,  16123,  11561])]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_trainingPredictor(2182)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(1.00000e-02 *\n",
       "        4.9290),\n",
       " tensor(9.8184),\n",
       " tensor(9.7882),\n",
       " tensor(9.7540),\n",
       " tensor(9.7217)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_trainingPredictor(start_hit):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = inputHits([start_hit])\n",
    "        rnn.hidden = rnn.init_hidden()\n",
    "        out_hits = []\n",
    "        pre_can = -1\n",
    "        for i in range(max_nhits):\n",
    "            output = rnn(input_tensor)\n",
    "            topv, topi = output.topk(3)\n",
    "            cand = topi[0][1]\n",
    "#             if cand <= pre_can:\n",
    "#                 break\n",
    "#             else:\n",
    "#                 pre_can = cand\n",
    "            if cand == total_modules:\n",
    "                print(\"Hit the last hits\")\n",
    "                break\n",
    "            else:\n",
    "                out_hits.append(topi[0])\n",
    "            input_tensor = inputHits([cand])\n",
    "        return out_hits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training with RNN\n",
    "example is taken from: [link](https://pytorch.org/tutorials/intermediate/char_rnn_generation_tutorial.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1m 3s (0 0%) 9.8356\n"
     ]
    }
   ],
   "source": [
    "n_iters = truth_particles.shape[0]\n",
    "\n",
    "n_iters = 1000\n",
    "n_iters = truth_particles.shape[0] if n_iters > truth_particles.shape[0] else n_iters\n",
    "print_every = n_iters/10\n",
    "# print_every = 1\n",
    "plot_every = 20\n",
    "all_losses = []\n",
    "total_loss = 0\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "rnn = RNN(total_modules+1, 512, total_modules+1)\n",
    "optimizer = optim.SGD(rnn.parameters(), lr=0.01)\n",
    "\n",
    "for iter_ in range(n_iters):\n",
    "    pID = truth_particles.values[iter_]\n",
    "\n",
    "    # prepare the inputs\n",
    "    input_, target_ = getInputTarget(training[training['particle_id'] == pID]['uID'].values)\n",
    "    \n",
    "    # training\n",
    "    rnn.zero_grad()\n",
    "    hidden = rnn.initHidden()\n",
    "   \n",
    "    loss = 0\n",
    "    for i in range(input_.size(0)):\n",
    "        tag_scores, hidden = rnn(input_[i], hidden)\n",
    "        loss += criterion(tag_scores, torch.tensor([target_[i]]))\n",
    "\n",
    "#     tag_scores, hidden = rnn(input_, hidden)\n",
    "#     loss = criterion(tag_scores, target_)\n",
    "        \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    norm_loss = loss/input_.size(0)\n",
    "    total_loss += norm_loss\n",
    "    if iter_ % print_every == 0:\n",
    "        print('%s (%d %d%%) %.4f' % (timeSince(start), iter_, iter_ / n_iters * 100, norm_loss))\n",
    "#         check_result(input_, tag_scores, target_)\n",
    "        \n",
    "    if iter_ % plot_every == 0:\n",
    "        all_losses.append(total_loss / plot_every)\n",
    "        total_loss = 0\n",
    "\n",
    "print(\"I am done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def check_training(start_hit):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = inputHits([start_hit])\n",
    "        print(input_tensor.size())\n",
    "        print(input_tensor[0][0][start_hit])\n",
    "        rnn.hidden = rnn.init_hidden()\n",
    "        out_hits = []\n",
    "        for i in range(max_nhits):\n",
    "            output = rnn(input_tensor)\n",
    "            topv, topi = output.topk(1)\n",
    "            topi = topi[0][0]\n",
    "            if topi == total_modules:\n",
    "                print(\"Hit the last hits\")\n",
    "                break\n",
    "            else:\n",
    "                out_hits.append(topi)\n",
    "            input_tensor = inputHits([topi])\n",
    "        return out_hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_trainingRNN(start_hit):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = inputHits([start_hit])\n",
    "        hidden = rnn.initHidden()\n",
    "        out_hits = []\n",
    "        topi = start_hit\n",
    "        for i in range(max_nhits):\n",
    "#             print(input_tensor.size())\n",
    "#             print(input_tensor[0][0][topi])\n",
    "            print(topi)\n",
    "            output, hidden = rnn(input_tensor[0], hidden)\n",
    "            # print(output)\n",
    "            # print(output.size())\n",
    "            topv, topi = output.topk(3)\n",
    "#             topi = topi[0][1]\n",
    "            if topi[0][0] == total_modules:\n",
    "                print(\"Hit the last hits\")\n",
    "                break\n",
    "            else:\n",
    "                out_hits.append(topi[0])\n",
    "            topi = topi[0][0]\n",
    "            input_tensor = inputHits([topi])\n",
    "        return out_hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1150\n",
      "tensor(1150)\n",
      "tensor(1150)\n",
      "tensor(1150)\n",
      "tensor(1150)\n",
      "tensor(1150)\n",
      "tensor(1150)\n",
      "tensor(10643)\n",
      "tensor(1150)\n",
      "tensor(1150)\n",
      "tensor(1150)\n",
      "tensor(1150)\n",
      "tensor(1150)\n",
      "tensor(1150)\n",
      "tensor(1150)\n",
      "tensor(10643)\n",
      "tensor(2336)\n",
      "tensor(3348)\n",
      "tensor(12162)\n",
      "tensor(12162)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[tensor([  1150,  10643,   2336]),\n",
       " tensor([  1150,  10643,   2336]),\n",
       " tensor([  1150,  10643,   2336]),\n",
       " tensor([  1150,  10643,   2336]),\n",
       " tensor([  1150,  10643,   2336]),\n",
       " tensor([  1150,  10643,   2336]),\n",
       " tensor([ 10643,   2336,  12162]),\n",
       " tensor([  1150,   2336,  18164]),\n",
       " tensor([  1150,  10643,  12162]),\n",
       " tensor([  1150,  10643,   2336]),\n",
       " tensor([  1150,  10643,   2336]),\n",
       " tensor([  1150,  10643,   2336]),\n",
       " tensor([  1150,  10643,   2336]),\n",
       " tensor([  1150,  10643,   2336]),\n",
       " tensor([ 10643,   2336,  12162]),\n",
       " tensor([  2336,  18164,  12162]),\n",
       " tensor([  3348,  12162,   2336]),\n",
       " tensor([ 12162,   2336,   3453]),\n",
       " tensor([ 12162,   7141,   2336]),\n",
       " tensor([ 12162,   2608,   2336])]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_trainingRNN(1150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(rnn.state_dict(), \"trained_1event_rnn_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(127.8480)\n"
     ]
    }
   ],
   "source": [
    "input_, target = randomTrack()\n",
    "rnn = HitPredictor(input_dim=total_modules+1, hidden_dim=128, output_dim=total_modules+1)\n",
    "\n",
    "#target.unsqueeze_(-1)\n",
    "rnn.hidden = rnn.init_hidden()\n",
    "\n",
    "rnn.zero_grad()\n",
    "loss = 0\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "for i in range(input_.size(0) - 1):\n",
    "    output = rnn(input_[0].view(1, 1, -1))\n",
    "    loss += criterion(output, torch.tensor([target[i]]))\n",
    "    \n",
    "\n",
    "# print(\"input size:\", input_.size())\n",
    "# print('target size:', target.size())\n",
    "# output = rnn(input_)\n",
    "# print(\"output size:\", output.size())\n",
    "# print(target)\n",
    "# loss = criterion(output, target)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_, target = randomTrack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-38-24a2ed7d7105>, line 18)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-38-24a2ed7d7105>\"\u001b[0;36m, line \u001b[0;32m18\u001b[0m\n\u001b[0;31m    print(loss)\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "rnn = RNN(total_modules+1, 3, total_modules+1)\n",
    "\n",
    "#target.unsqueeze_(-1)\n",
    "hidden = rnn.initHidden()\n",
    "\n",
    "rnn.zero_grad()\n",
    "loss = 0\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "print(\"input size:\", input_.size())\n",
    "print('target size:', target.size())\n",
    "output, hidden = rnn(input_[0], hidden)\n",
    "print(\"output size:\", output.size())\n",
    "print(target)\n",
    "print(target[0])\n",
    "loss = criterion(output, torch.tensor([target[0]]))\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1\n"
     ]
    }
   ],
   "source": [
    "print(output.size(0), torch.tensor([target[0]]).size(0))\n",
    "loss = criterion(output, torch.tensor([target[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1])\n",
      "torch.FloatTensor\n",
      "torch.float32\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-a5513195d698>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mh0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mc0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mh0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/global/project/projectdirs/m1092/xju/miniconda3/envs/py3.6/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/global/project/projectdirs/m1092/xju/miniconda3/envs/py3.6/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0mbatch_sizes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             \u001b[0mmax_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_first\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "rnn2 = nn.LSTM(6, 20)\n",
    "input = torch.randn(1)\n",
    "print(input.size())\n",
    "print(input.type())\n",
    "print(input.dtype)\n",
    "h0 = torch.randn(2, 1, 20)\n",
    "c0 = torch.randn(2, 1, 20)\n",
    "output, hn = rnn2(input, (h0, c0))\n",
    "print(output)\n",
    "print(output.size())\n",
    "print(hn)\n",
    "print(hn[0].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.LogSoftmax(dim=1)\n",
    "loss = nn.NLLLoss()\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.tensor([1, 0, 4])\n",
    "print(target.size())\n",
    "print(m(input).size())\n",
    "output = loss(m(input), target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1,  2,  4,  5])\n"
     ]
    }
   ],
   "source": [
    "embedding = nn.Embedding(10, 3)\n",
    "input = torch.LongTensor([1,2,4,5])\n",
    "print(input)\n",
    "embeds = embedding(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3])\n",
      "torch.Size([4])\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "print(embeds.size())\n",
    "print(input.size())\n",
    "print(len(input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5956, -0.3846,  0.6718],\n",
      "        [ 0.4788,  0.3929,  0.4087],\n",
      "        [ 0.3090,  0.4232,  1.3487],\n",
      "        [ 2.1231, -0.9157, -1.3121]])\n",
      "tensor([[[-0.5956, -0.3846,  0.6718]],\n",
      "\n",
      "        [[ 0.4788,  0.3929,  0.4087]],\n",
      "\n",
      "        [[ 0.3090,  0.4232,  1.3487]],\n",
      "\n",
      "        [[ 2.1231, -0.9157, -1.3121]]])\n",
      "torch.Size([4, 1, 3])\n"
     ]
    }
   ],
   "source": [
    "print(embeds)\n",
    "new_embeds = embeds.view(len(input), 1, -1)\n",
    "print(new_embeds)\n",
    "print(new_embeds.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of HitPredictor(\n",
       "  (lstm): LSTM(18729, 128)\n",
       "  (fc): Linear(in_features=128, out_features=18729, bias=True)\n",
       "  (dropout): Dropout(p=0.1)\n",
       "  (softmax): LogSoftmax()\n",
       ")>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "a_list = [1, 3,4 ,45]\n",
    "with open('outfile', 'wb') as fp:\n",
    "    pickle.dump(a_list, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 4, 45]\n"
     ]
    }
   ],
   "source": [
    "with open('outfile', 'rb') as fp:\n",
    "    my_list = pickle.load(fp)\n",
    "    print(my_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total parameters: 12071849\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
